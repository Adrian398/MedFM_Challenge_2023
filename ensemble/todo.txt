For colon:
When training new models:
    1 log ACCURACY
    2 save best ACCURACY

For chest / endo:
When training new models:
    1 log mAP
    2 Save best MAP

In general:
1 Add copying of used configs to some directory in the submission directory (or add a report summarizing used models)
2 Local validation:
    - download annotations for validation data
    - make inferences on validation data => 2 csvs per run script
    - make sure infer_missing_predictions is adjusted, so it checks for the correct csv (not just any)
    - adapt ensemble/submission to use inferences on validation data to create ensemble result =>
        - Write custom evaluation of these results (can't use Runner / test script, cause that requires one model,
        we have csvs from multiple models)